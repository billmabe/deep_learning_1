#load packages
library(h2o)
library(ggplot2)

#set number of threads to number of available cores
h2o.init(nthreads = -1, max_mem_size = '50g')

#start log
h2o.startLogging()

#download data
train_file <- "https://h2o-public-test-data.s3.amazonaws.com/bigdata/laptop/mnist/train.csv.gz"
test_file <- "https://h2o-public-test-data.s3.amazonaws.com/bigdata/laptop/mnist/test.csv.gz"

#create train, validation, and test sets
train1<- h2o.importFile(train_file)
inValid <- sample(nrow(train1), 10000, replace = FALSE)
train <- train1[-inValid, ]
#valid <- train1[inValid, ]
test <- h2o.importFile(test_file)

#create x matrix and y (response) vector
y <- "C785"
x <- setdiff(names(train), y) #What's in x that's not in y

#recode response column to factor for multinomial classification
train[,y] <- as.factor(train[,y])
#valid[,y] <- as.factor(valid[,y])
test[,y] <- as.factor(test[,y])

#parameters for grid search function
hidden_opt <- list(c(32,32), c(32,16,8), c(50)) #first try
#hidden_opt <- list(c(500), c(100,100), c(100)) #second try
#hidden_opt <- list(c(250), c(100,100,100), c(100,100)) #third try

l1_opt <- c(1e-4,1e-3)
#l1_opt <- c(1e-3) #second try

hyper_params <- list(hidden = hidden_opt, l1 = l1_opt)

#create grid search function
deep_learn_grid_search <- function(n) {
	model_grid_b <- h2o.grid(
	"deeplearning",
	grid_id = paste0("grid_number_",n),
	hyper_params = hyper_params,
	x = x,
	y = y,
	distribution = "multinomial",
	training_frame = train,
	validation_frame = test, #better to run with nfolds when doing hyper parameter optimizations????
	score_interval = 2,
	epochs = 10,
	stopping_rounds = 3,
	stopping_tolerance = 0.05,
	stopping_metric = "misclassification",
	nfolds = n,
	keep_cross_validation_predictions = TRUE,
	overwrite_with_best_model = TRUE)
}

model_list <- list()
for(i in 2:20){
	model_list[[i-1]] <- deep_learn_grid_search(i)
	} 

#loop through H2OGrid objects and calculate mse for each model
mse <- NULL
for(i in 1:length(model_list)) {
for (model_id in model_list[[i]]@model_ids) {
	mse <- rbind(mse,cbind(model_id,h2o.mse(h2o.getModel(model_id), valid = TRUE)))
}}

#Clean the mse object after it has been populated with the results 
row.names(mse) <- NULL
mse_df <- as.data.frame(mse)
mse_df$model_id <- as.character(mse_df$model_id)
mse_df$V2 <- as.numeric(as.character(mse_df$V2))
mse_df_new <- data.frame(cbind(substr(mse_df$model_id,1,14),substr(mse_df$model_id,15,nchar(model_id)),mse_df$V2))
mse_df_new$X1 <- as.character(gsub("_","",mse_df_new$X1))
mse_df_new$X1 <- as.numeric(as.character(gsub("gridnumber","",mse_df_new$X1)))
mse_df_new$X2 <- as.character(gsub("_","",mse_df_new$X2))
mse_df_new$X3 <- as.numeric(as.character(mse_df_new$X3))
names(mse_df_new) <- c("Grid_Number", "Model_Number", "mse")

#plot
ggplot(mse_df_new, aes(x = Grid_Number, y = mse, levels = Model_Number)) +
    geom_line(aes(colour = Model_Number)) +
    xlab("Number of nfolds in Cross Validation") + 
    ylab("Mean Square Error")

#mean of mse across all runs of nfolds
aggregate(mse_df_new$mse ~ mse_df_new$Model_Number, FUN = mean)

h2o.stopLogging()
h2o.openLog("Command")
h2o.openLog("Error")
sessionInfo()
