#load packages
library(h2o)
library(ggplot2)

#set number of threads to number of available cores
h2o.init(nthreads = -1, max_mem_size = '50g')

#start log
h2o.startLogging()

#download data
train_file <- "https://h2o-public-test-data.s3.amazonaws.com/bigdata/laptop/mnist/train.csv.gz"
test_file <- "https://h2o-public-test-data.s3.amazonaws.com/bigdata/laptop/mnist/test.csv.gz"

#create train, validation, and test sets
train1<- h2o.importFile(train_file)
inValid <- sample(nrow(train1), 10000, replace = FALSE)
train <- train1[-inValid, ]
#valid <- train1[inValid, ]
test <- h2o.importFile(test_file)

#create x matrix and y (response) vector
y <- "C785"
x <- setdiff(names(train), y) #What's in x that's not in y

#recode response column to factor for multinomial classification
train[,y] <- as.factor(train[,y])
#valid[,y] <- as.factor(valid[,y])
test[,y] <- as.factor(test[,y])

#parameters for grid search function
hidden_opt <- list(c(32,32), c(32,16,8), c(50)) #first try
#hidden_opt <- list(c(500), c(100,100), c(100)) #second try
#hidden_opt <- list(c(250), c(100,100,100), c(100,100)) #third try

l1_opt <- c(1e-4,1e-3)
#l1_opt <- c(1e-3) #second try

hyper_params <- list(hidden = hidden_opt, l1 = l1_opt)

#create grid search function
deep_learn_grid_search <- function(n) {
	model_grid_b <- h2o.grid(
	"deeplearning",
	grid_id = paste0("grid_number_",n),
	hyper_params = hyper_params,
	x = x,
	y = y,
	distribution = "multinomial",
	training_frame = train,
	validation_frame = test, #better to run with nfolds when doing hyper parameter optimizations????
	score_interval = 2,
	epochs = 1,
	stopping_rounds = 3,
	stopping_tolerance = 0.05,
	stopping_metric = "misclassification",
	nfolds = n,
	keep_cross_validation_predictions = TRUE,
	overwrite_with_best_model = TRUE)
}

model_list <- list()
for(i in 2:20){
	model_list[[i-1]] <- deep_learn_grid_search(i)
	} 

#loop through H2OGrid objects and calculate mse for each model
mse <- NULL
for(i in 1:length(model_list)) {
	for (model_id in model_list[[i]]@model_ids) {
		mse <- rbind(mse,cbind(model_id,h2o.mse(h2o.getModel(model_id), valid = TRUE)))
}} 
#NOTE: mse is a character matrix

#Clean the mse object after it has been populated with the results 
row.names(mse) <- NULL
mse_df <- data.frame(mse[,1],as.double(mse[,2]), stringsAsFactors = FALSE)
save(mse_df, file = "mse.RData")

mse_df_new <- data.frame(substr(mse_df[,1],1,14),substr(mse_df[,1],15,nchar(mse_df[,1])),mse_df[,2], stringsAsFactors = FALSE)
mse_df_new[,1] <- as.integer(gsub("[^0-9]","",mse_df_new[,1]))
mse_df_new[,2] <- as.factor(gsub("[^0-9]","",mse_df_new[,2]))
names(mse_df_new) <- c("Grid_Number", "Model_Number", "mse")
save(mse_df_new, file = "mse_df_new.RData")

#plot
plot <- ggplot(mse_df_new, aes(x = Grid_Number, y = mse, levels = Model_Number)) +
    geom_point(aes(colour = Model_Number), size = 3) + 
    geom_line(aes(colour = Model_Number), size = 1) +
    xlab("Number of nfolds in Cross Validation") + 
    ylab("Mean Squared Error") +
    scale_colour_brewer(name = "Model Number", palette = 3) +
    theme(
    legend.text = element_text(size=10),
    legend.title = element_text(size=12),
    axis.text.x = element_text(size=10),
    axis.text.y = element_text(size=10),
    axis.title.x = element_text(size=12),
    axis.title.y = element_text(size=12)
    )
    
plot

#mean of mse across all runs of nfolds
aggregate(mse_df_new$mse ~ mse_df_new$Model_Number, FUN = mean)

h2o.stopLogging()
h2o.openLog("Command")
h2o.openLog("Error")
sessionInfo()
